IEEE TRANSACTIONS ON INFORMATION FORENSICS AND SECURITY, VOL. 19, 2024 5925
RFTrack: Stealthy Location Inference and Tracking
Attack on Wi-Fi Devices
Ronghua Li , Haibo Hu , Senior Member, IEEE, and Qingqing Ye , Member, IEEE
Abstract— We present RFTrack, a new indoor location inference attack on Wi-Fi devices. This attack differs from existing Wi-Fi localization methods as it does not need bulky appliance deployment or inner physical access to the place of interest. RFTrack distinguishes itself by leveraging the temporal sequence of unlabeled Received Signal Strength Indicator (RSSI) values to deduce location labels. To achieve this, we deploy a Reinforcement Learning (RL) agent to model the most likely path of device movement and utilize these modeled trajectories to construct an RSSI fingerprint map. To enhance the accuracy of trajectory reconstruction, our technique exploits certain stationary Wi-Fi devices within the target area as reference points, facilitating the assessment of whether the mobile devices have traversed near specific zones with a newly proposed metric, the RSSI difference. The experimental results demonstrate that our system can accurately recover the trends of moving trajectories and successfully associate the unlabeled RSSI values with positions inside the place of interest to build a fingerprint map for real-time device tracking.
Index Terms— Indoor tracking, location privacy, reinforcement learning.
I. INTRODUCTION
W
I-FI-ENABLED mobile and IoT devices have become ubiquitous, primarily due to reduced manufacturing costs and the widespread adoption of wireless protocols. These devices, which include mobile phones and smartwatches, are now an integral part of daily life for many individuals. However, the continual signal transmission from such devices poses a significant risk to location privacy. For instance, individuals of public interest often seek to conceal their whereabouts from intrusive media scrutiny. Additionally, the general citizens face risks such as break-ins and theft in areas devoid of surveillance mechanisms. One may leave personal valuables unattended in office spaces, rendering them susceptible to theft. While a burglar wandering outside might arouse suspicion and risk apprehension, the ability to peek at people’s location and room occupancy from afar significantly lowers the his risk of detection [1], [2].
Manuscript received 21 September 2023; revised 8 April 2024; accepted 14 May 2024. Date of publication 23 May 2024; date of current version 31 May 2024. This work was supported in part by the National Natural Science Foundation of China under Grant 62072390, Grant 62102334, and Grant 92270123; and in part by the Research Grants Council, Hong Kong, SAR, China, under Grant 15218919, Grant 15203120, Grant 15226221, Grant 15225921, and Grant C2004-21GF. The associate editor coordinating the review of this manuscript and approving it for publication was Dr. Andrew Clark. (Corresponding author: Haibo Hu.)
The authors are with the Department of Electrical and Electronic Engineering, The Hong Kong Polytechnic University, Hong Kong (e-mail: cory-ronghua.li@connect.polyu.hk; haibo.hu@polyu.edu.hk; qqing.ye@polyu.edu.hk). Digital Object Identifier 10.1109/TIFS.2024.3404810
Fig. 1. RFTrack system overview.
While there exists a substantial body of research on Wi-Fi-based indoor localization, these methods exhibit limitations when applied in adversarial settings, especially in tracking scenarios. For instance, model-based methods, such as [3] and [4], necessitate a massive deployment of Access Points (APs) to ensure line of sight (LOS) to the target devices to counter the multi-path effect. In addition, the APs used in some studies are not only powerful but also bulky, making them easily detectable. Moreover, fingerprint-based approaches demand the time-consuming task of gathering labeled data within the place of interest (PoI). This step becomes impractical in numerous adversarial contexts where attackers might not have complete access to the PoI. In this work, we delve into adversarial localization and present RFTrack, an indoor location inference and tracking attack targeting Wi-Fi devices. This attack allows for consistent localization and tracking of an indoor Wi-Fi device using just a few sniffers positioned outside the PoI. RFTrack is distinguished by two key features: (i) it’s stealthy — the adversarial devices deployed are inconspicuous and operate without the need for cooperated communication, rendering them difficult to detect; and (ii) it’s real-time — the system can constantly track target devices. The goal of this research is to bring to the forefront concerns about potential location privacy leakages for both the general public and wireless protocol designers. Fig. 1 provides an overview of the RFTrack system. At first, attackers set up a transmitter and several sniffers outside the PoI. Using the Wi-Fi packet collection method detailed in [5], they identify target devices and gather RSSI sequence data. A central tenet of RFTrack is the observation that as a device moves indoors, it may revisit certain locations. At these
1556-6021 © 2024 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See https://www.ieee.org/publications/rights/index.html for more information.
Authorized licensed use limited to: Southeast University. Downloaded on November 22,2024 at 08:07:19 UTC from IEEE Xplore. Restrictions apply.


5926 IEEE TRANSACTIONS ON INFORMATION FORENSICS AND SECURITY, VOL. 19, 2024
recurrent points, RSSI values are likely to display similar patterns. By exploiting these patterns with deep reinforcement learning (DRL), attackers can recover the movement trajectories of the target device. Then, attackers could map the gathered unlabeled RSSI sequences to these recovered trajectories to construct a “virtual” RSSI fingerprint map, enabling real-time tracking. For clarity, in this paper, we use the terms “path” and “trajectory” interchangeably.
Why Fingerprint & Why RSSI? First, a fingerprint-based method can provide accurate and instant localization once the fingerprint is built, and it does not require deploying many APs to mitigate the impact of the multipath effect as opposed to model-based methods. Therefore, fingerprint-based methods are more suitable for an adversarial scenario. Second, RSSI emerges as the most stable and accurate fingerprint feature after proper data processing. For instance, channel state information (CSI) is too sensitive to changes in the surroundings. In [5], ToF is measured with high stability using ESP32 [6], which however cannot be reproduced. Nonetheless, these features with less stability may be treated as additional fingerprint information to RSSI and increase the overall RFTrack performance, which is beyond the scope of this work. The main challenge of RFTrack is to build a fingerprint map without free access to labeled data inside the PoI. To address this challenge, we propose the following two methods:
(i) Self-Consistency Rewarding Mechanism for DRL While it is hard to directly obtain known features inside the PoI (e.g., landmarks, labeled position), we design a consistency-based rewarding mechanism for DRL. We noticed that as users move, their devices produce varying RSSI values, with similar values often corresponding to proximate positions. This observation led us to simulate possible movement trajectories for the target devices using DRL agents. If a trajectory maintains self-consistency, the corresponding RSSI values should show resemblance whenever the agent revisits the same or nearby locations. Through this approach, we bridge the gap between RSSI values and physical positions, essentially allowing RSSI data to “self-label” with corresponding positions.
(ii) Static Anchors as Reference Labeled Positions To further enhance the accuracy of location labels, we use static Wi-Fi devices inside the PoI as reference anchors (RA) to assist the tracking. Initially, we pinpoint the location of these static anchors using enhanced adversarial dead reckoning. Subsequently, we assess whether the moving target devices are in close proximity to these RAs. However, due to the great variance of device-dependent transmitting characteristics, features such as RSSI cannot be directly used to determine physical proximity between devices. Given that attackers may have more than one sniffer, we propose to use a new metric, RSSI difference, for signal mapping. Despite the different transmitting power, devices exhibit similar patterns of RSSI differences at close positions. Consequently, this characteristic enables us to leverage the reference anchors to enhance the tracking accuracy of target devices. In conclusion, we introduce RFTrack, an attack that employs reinforcement learning to construct a fingerprint map for the
place of interest using unlabeled RSSI sequences. Our main contributions are listed as follows: • We propose a metric for reliable adversarial dead reckoning localization. Initially, RFTrack determines the positions of targeted devices and Reference Anchors (RAs) utilizing an adversarial dead reckoning approach. To enhance the precision of these results, we suggest the implementation of the final loss value as a measure to ascertain the reliability of the findings, which significantly augments the overall accuracy of RFTrack by excluding less dependable results. • We propose another metric, namely RSSI difference, to ascertain the physical proximity of target Wi-Fi devices to other entities, specifically RAs. Such a metric diminishes the impact of distinct device transmission traits and concentrates solely on the similarity of signal propagation environments between the target device and an RA. • We design an RL-based method for RSSI fingerprinting with unlabeled data. Given the restrictions on access to the PoI, our approach leverages reinforcement learning to reconstruct potential movement patterns of users and to fingerprint the PoI using pre-collected unlabeled RSSI sequences. This methodology was tested in two distinct indoor environments to validate its effectiveness and to demonstrate its capacity for achieving consistent tracking. The rest of this paper is organized as follows. Some related works are reviewed in Sec. II. In Sec. III, we define the attacking scenario and the threat model. In Sec. IV, we explain the design intuitions and the overview procedure of RFTrack. Details of RFTrack are in Sec. V and Sec. VI. In Sec. VII, we introduce our experiment setup and evaluate RFTrack’s system performance. In Sec. VIII, we further discuss the limitations, future improvements, and possible mitigation mechanisms.
II. RELATED WORKS
Wireless indoor localization has been investigated extensively in the past decades [7], [8]. While researchers have paid excessive efforts to protect individual’s (location) data privacy in data collection and aggregation [9], [10], [11], information leakage directly from wireless signals remains to be explored. In this section, we review recent works in related fields and explain the motivation for our designed approach.
A. Indoor Localization
Wi-Fi localization techniques are broadly categorized into model-based [3], [12], [13], [14] and fingerprint-based [15], [16], [17] approaches. Model-based strategies determine device locations by simulating the propagation of wireless signals, utilizing models such as Time-of-Flight (ToF) [12], [18], Angle-of-Arrival (AoA) [3], [13], [14], [19], and Time-Difference-of-Arrival (TDoA) [20]. Xiong and Jamieson proposed an accurate AoA-based indoor localization method using bulky access points (AP) consisting of a wide antenna array [3], though the proposed approach is limited by their AP’s bulkiness. Addressing this, Kotaru et al. introduced
Authorized licensed use limited to: Southeast University. Downloaded on November 22,2024 at 08:07:19 UTC from IEEE Xplore. Restrictions apply.


LI et al.: RFTrack: STEALTHY LOCATION INFERENCE AND TRACKING ATTACK ON Wi-Fi DEVICES 5927
SpotFi, which employs both AoA and ToF but uses commercially available Wi-Fi routers instead, facilitating denser AP deployment and enhancing localization precision [4]. To further simplify the deployment of AP, Vasisht et al. proposed Chronous to merge AoA and ToF by analyzing the fundamental reason for using multiple APs in wireless localization and achieve localizing devices with only one AP [12]. However, despite the effectiveness of model-based localization methods, their applicability in adversarial settings is limited. Highprecision systems, such as those based on ToF or AoA, often depend on Line-of-Sight (LOS) paths to minimize the influence of multipath effects [21], which are critical for accurately determining the distance or angle between an AP and a device. For instance, SpotFi [4], stating to be adaptable to a high Non-Line-of-Sight (NLOS) scenario, still demands one or two LOS paths. This prerequisite is impractical for adversarial AP deployments, rendering model-based approaches less suitable for privacy intrusion attempts. Another mainstream, the fingerprint-based localization method, capitalizes on the consistent characteristics of wireless signals emitted by the same device at identical locations, including RSSI and channel state information (CSI) [15], [16], [17]. These methods typically leverage the power of deep learning to achieve precise localization [15], [16], [17]. However, they necessitate extensive data collection within the area of interest beforehand, a task that is both labor-intensive and requires access to the premises (PoI). Such a need for PoI access restricts attackers from readily utilizing these models. While techniques such as data augmentation [22] aim to alleviate the data collection burden, a significant amount of labeled data from the PoI remains essential. In summary, the collection procedure of labeled RSSI data impedes the direct adoption of fingerprint-based methods in adversarial contexts.
B. Location Privacy Breach
Due to the proliferation of mobile devices, device location privacy breach has been broadly researched from the perspective of protection [23], [24], [25], [26], [27] and attack [5], [28], [29], [30], [31], [32], [33]. On the one hand, benign location-based services are designed to provide user utility while safeguarding location and identity privacy [34], [35], [36], [37], [38], [39]. On the other hand, early efforts, such as [40] exploits IEEE 802.11 probe requests to adversarially uncover user outdoor movements at the street level. Meanwhile, indoor location privacy breach has also been a significant concern, with some attacks [33] leveraging deep learning to interpret motion sensor data from mobile devices, thereby inferring movement along indoor corridors. However, such corridors are generally accessible, somewhat mitigating the perceived threat of these attacks. In contrast, Zhu et al. introduced a more invasive method [31], the continuous room-level peeping attack, which monitors Channel State Information (CSI) amplitude changes caused by room occupancy, enabling attackers to deduce the presence of individuals without needing physical access to the space. This method, while effective in indicating occupancy, lacks the ability to differentiate between various types of occupants,
such as humans, pets, or robotic devices. Building on these concepts, Abedi and Vasisht developed Wi-Peep, an advanced localization attack using a drone equipped with a Wi-Fi emitter and sniffer [5]. This approach calculates the Time of Flight (ToF) from target devices at various drone positions to pinpoint their location. Despite its precision, this method only supports one-time localization, limited by the drone’s battery constraints, necessitating frequent landings for recharging. This backdrop sets the stage for our work, which aims to surpass the limitations of existing methods by devising an adversarial attack capable of persistent indoor device tracking. By strategically positioning a few APs outside the PoI, our approach facilitates continuous monitoring, representing a more severe breach of privacy compared to episodic localization attacks.
C. Deep Reinforcement Learning
Since the great success of AlphaGo, deep reinforcement learning (DRL) has attracted enormous attention. DRL combines two components: Deep Learning (DL) and Reinforcement Learning (RL). RL is a machine learning algorithm that lets an agent interact with environments (primarily games) and learn how to perform better according to the feedback through iterations [41]. A DL model helps the RL with more complex environments to solve even an NP-hard problem [42]. While DRL has been extensively studied for navigation systems [43], [44], it is not studied in depth for localization purposes. The main idea of localizing devices with DRL is to build an RSS (or other features) fingerprint map, and the biggest challenge is the design of rewarding mechanisms. Reference [45] proposed a semisupervised DRL method. Part of the data is labeled with specific locations and can be used as reference points for rewarding the agent when the agent approaches these places. Later, [46] proposed a system that does not require pre-labeled data. The system owns many landmarks in the PoI and rewards the agent based on the simulated physical proximity between the agent and landmarks, and the closeness of their real RSS measurements. However, using such frameworks in adversarial scenarios is impractical since neither the partially labeled data nor the landmark inside the PoI is available to attackers, rendering the need for a new reward mechanism in adversarial contexts.
III. THREAT MODEL
In RFTrack’s attack scenario, an attacker targets an indoor location (PoI). A Wi-Fi AP within the PoI connects user devices to the Internet using the IEEE 802.11 protocol. To intercept signals from target devices, the attacker places Wi-Fi sniffers close to the PoI. These sniffers consistently record the devices’ RSSI sequences. Though lacking direct access to the PoI, attacker are free to walk or drive surrounding the PoI in the bootstrapping phase. Attackers might also glean insights into the internal structures of the PoI using social engineering tactics, like shoulder surfing, though the precise locations of these structures remain uncertain. Regarding indoor movement, we make a few practical assumptions. First, indoor movements are usually purposeful, contrasting with the random patterns seen outdoors. Thus,
Authorized licensed use limited to: Southeast University. Downloaded on November 22,2024 at 08:07:19 UTC from IEEE Xplore. Restrictions apply.


5928 IEEE TRANSACTIONS ON INFORMATION FORENSICS AND SECURITY, VOL. 19, 2024
users typically move within spaces or transition between them. Second, indoor walking speeds are inherently limited, confining the extent of areas users can cover within a set timeframe. Through the procedure, attackers attempt to build an RSSI fingerprint map for the PoI. We assume that attackers can get a rough 2D floor plan of the PoI, which only shows fixed obstacles such as walls and is normally open access to the public from building authorities or real estate agencies. Observable detailed structures within the PoI can be incorporated into this floor plan to further refine the reachable areas, but their preciseness cannot be measured.
IV. OVERVIEW ON RFTRACK
This section overviews our RFTrack attack system, including the design intuition, design objectives, and system workflow. The next two sections will elaborate on the main procedures of RFTrack.
A. Design Intuition
The main challenge in RFTrack is to build a fingerprint map with the collected sequences of unlabeled RSSI. We rely on the following two key ideas to address this challenge. Firstly, Wi-Fi devices within the PoI act as anchors, determining the proximity of other devices to specific areas. At least one stationary Wi-Fi AP exists inside the PoI, alongside other fixed devices such as smart speakers and IP cameras. By identifying the locations of these reference devices, the proximity of target devices can be assessed using a new metric: the RSSI difference. This allows us to fingerprint areas adjacent to these Reference Anchors (RAs). Secondly, to map areas without RAs, we employ a consistency-based approach. This is rooted in the observation that devices in particular locations consistently exhibit similar RSSI values. Within a continuous RSSI sequence, if a device revisits a location or its surroundings, certain “moments” in the sequence will display consistent values. Importantly, these “moments” are unique for each sequence because a device might revisit different locations at different moments, leading to varied movement trajectories. This unique temporal information buried in the RSSI sequence, named “consistency information,” correlates to the device’s movements, providing insights into its location. Fig. 2 depicts the method of deducing a device’s movements through consistency. The left side of the figure shows a ground-truth path representing the actual movement of the target device. During this movement, an associated “ground-truth RSSI sequence” is captured by sniffers. Although attackers lack knowledge of these actual movements, they can simulate possible paths. The figure’s right side presents two simulated paths that share the same first-half forwarding (the blue curve) but own different backward movements (the red and the green curve). To validate the two guesses, we apply consistency checking on them by mapping the ground truth RSSI sequence to the two paths separately, i.e., R SS I1 to the first grid, R SS I2 to the second grid, etc. If we assume the red curve represents the true path, RSSI values mapped to identical grids, like
Fig. 2. Explanation of “consistency”. The left side is the ground-truth path. The right side are simulated paths.
R SS I11 and R SS I4 (associated with the red grid), should be similar. However, this is not the case. As a result, even though attackers do not know the ground-truth path, they validate their guesses via consistency checking. Only the trajectories that are correct, or nearly so, will exhibit strong self-consistency, as demonstrated by the green curve.
B. Overall Procedure of RFTrack
In the following sections, we elaborate on the detailed procedures of RFTrack, which must achieve the following objectives: • OBJ1: RFTrack continuously senses Wi-Fi signals from devices inside the PoI. • OBJ2: RFTrack has a procedure to initially localize Wi-Fi devices, i.e., RAs and target devices, different from the following real-time localization and tracking. • OBJ3: The proximity between two Wi-Fi devices can be determined by a new metric, namely, RSSI difference. • OBJ4: RFTrack builds a system that can simulate trajectories and verifies them with consistency checking. It uses the recovered trajectories to build a fingerprint map. • OBJ5: RFTrack locates and tracks target devices with the fingerprint map. The workflow of RFTrack is as follows. Above all, RFTrack relies on RSSI data collection as a building block. We adopt the method in [5] and briefly introduce it in Sec. V (OBJ1). On top of RSSI data collection, RFTrack has four phases: bootstrap, data collection, fingerprint building (FB), and tracking. • (I) Bootstrap Attackers use dead reckoning to initially locate target devices and RAs and statically deploy their adversarial devices (OBJ2, see Sec. V-A). • (II) Data Collection Attackers use the deployed adversarial devices to collect RSSI data from target devices inside PoI, whether or not the targets move (see Sec. V). • (III) Fingerprint Building Attackers use the RSSI sequences collected at the data collection phase (DCP) to build a fingerprint map. There are three sub-routines in this phase. In Sec. VI-A, attackers preprocess the RSSI sequence data, including smoothing and identifying moving periods of the target devices during DCP. Next, in Sec. VI-B, attackers use the processed RSSI data to detect the proximity of target devices to one of the RAs during DCP, evaluated by RSSI difference (OBJ3). Last, in Sec. VI-C, attackers build a Reinforcement learning system to recover the ground truth trajectories at DCP to build a fingerprint map (OBJ4).
Authorized licensed use limited to: Southeast University. Downloaded on November 22,2024 at 08:07:19 UTC from IEEE Xplore. Restrictions apply.


LI et al.: RFTrack: STEALTHY LOCATION INFERENCE AND TRACKING ATTACK ON Wi-Fi DEVICES 5929
• (IV) Device Tracking Attackers use the fingerprint map to track target devices in Sec. VI-D (OBJ5).
V. BOOTSTRAP & DATA COLLECTION
We introduce the data collection method and the first two phases of RFTrack in this section. RFTrack is built on a similar RSSI data collection method as Wi-Peep [5]. This method leverages a vulnerability in the IEEE 802.11 protocol to solicit responses from target devices in an interactive but non-cooperative manner. Specifically, when a target device is connected to an AP, attackers can elicit ACK responses by setting the “destination address” field in spoofed Null Data packets (NDP) to the target’s MAC address. In contrast to [5], such an approach requires an additional step: setting the “source address” field in the spoofed NDP to the AP’s MAC address. Moreover, our spoofed NDP has a unique “BSSID” field, distinguishing it from the standard NDPs sent by the AP. Such a method offers two advantages. First, since there is no packet injection into the network, network firewalls or intrusion detection systems would not generate any alert, which keeps the attacking devices stealthy. Second, such a method forces target devices to transmit packets at a higher frequency than regular communication, which facilitates subsequent procedures. In our implementation, we use an ESP32 device [6] to send spoofed Wi-Fi packets at a fixed frequency and another ESP32 to sniff and record RSSI values of targets’ responses.
A. Bootstrap
Bootstrap is the starting point of RFTrack. In this phase, attackers initially pinpoint locations of target devices and reference anchors and deploy their adversarial transmitter and sniffers, i.e., ESP32 devices. To achieve the localization, attackers use a dead reckoning process and the Log-distance Path Loss (LDPL) model, similar to previous works [31], [47]. Importantly, we enhance this dead reckoning approach for the attackers by integrating a result reliability assessment, which we outline next.
1) Reference Anchors and Target Devices Localization: LDPL model is a wireless signal propagation model, where the received signal strength (RSS) decreases as the signal propagation range increases. Formally,
R S Sx,y = P0 − 10γ lg(dx,y)
dx,y =
√
(X0 − x)2 + (Y0 − y)2, (1)
where P0 and γ are constants based on the initial transmitting power and propagation environment, respectively, (X0, Y0) is the coordinate of the transmitter we want to locate, and (x, y) is the receiver’s coordinate. Given known constant parameters, the transmitter’s coordinate can be triangulated by measuring just several pairs of (x, y) and R SS. In scenarios where P0 and γ are unmeasurable, prior studies advocate using dead reckoning coupled with gradient descent to address this challenge [48], [49]. Thanks to dead reckoning, attackers can localize targets by wandering with a sniffer outside the PoI. Suppose that attackers measured n pairs of their coordinate
(x, y) and the sniffed RSSI, they can reveal targets locations, specifically, (X0, Y0), by determining the optimal parameters Pˆ0, γˆ , Xˆ0, and Yˆ0 that minimize a given loss function using gradient descent (GD).
Loss =
n
∑
i =1
∥ˆ
R S Six,y − R S Si
meas ur e ∥
2 (2)
Up until now, the model employed in previous research, like [48] and [49], has been effective in accurately pinpointing target locations. To adapt and enhance these methodologies for an adversarial context, we made the following observations: While standard localization typically aims for a consistent average performance, it may not ensure precision for every individual result. In adversarial settings, attackers prioritize high accuracy for specific results and can tolerate sporadic poor results if they can identify and ignore them or redo computations. For example, despite their high average performance, two previous adversarial works suffered from occasionally high localization errors [31], [47], which jeopardizes the attackers’ plans. To the best of our knowledge, no existing dead reckoning technique incorporates an assessment of result reliability or accuracy. To address this gap, we suggest utilizing the loss as a metric for evaluation. Our system adapts from [31]. We first use a Monte Carlo method to randomly initialize the LDPL model parameters in a GD epoch. In each epoch, The model converges to a local minimum (location) with the data selected by the data-sifting method in [31]. As shown in Fig. 3, blue dots represent outcomes of all epochs, among which some with final losses closer to the global minimum gather at a natural cluster, roughly covering the ground-truth location. To obtain finer results, we focus on bins that predominantly consist of dots from this cluster (captured with the red rectangle), within which we further select the bin with the lowest average loss as the final output. Moreover, we assess such a result’s reliability with the absolute loss at convergence. Higher losses imply lower reliability. As a result, attackers localize target devices and RAs not only accurately but also fully aware of the results’ reliability.
2) Positions of Sniffer Deployment: Upon completing the dead reckoning process, attackers must set up their transmitters and sniffers in fixed positions. The transmitter’s positioning is flexible and can be placed virtually anywhere. As for the sniffers, they can be stationed anywhere as long as they can detect signals emanating from the target devices. Nonetheless, attackers could extract more information by placing sniffers at specific positions. For instance, sniffers could detect the proximity of target devices based on their absolute RSSI values. In this work, we have not used such information in the experiments and may integrate it into the system in the future.
B. Data Collection
After the bootstrap, sniffers start sensing target devices’ signals and recording their RSSI values. During data collection, users may carry their devices and move inside the PoI, where their movements are the ground-truth trajectories that RFTrack
Authorized licensed use limited to: Southeast University. Downloaded on November 22,2024 at 08:07:19 UTC from IEEE Xplore. Restrictions apply.


5930 IEEE TRANSACTIONS ON INFORMATION FORENSICS AND SECURITY, VOL. 19, 2024
Fig. 3. Bootstrap localization of reference anchors and target devices. Coordinates are in meters.
Fig. 4. RSSI sequence data.
aims at recovering, as illustrated in Sec. IV-A. At any moment, attackers can gather the sequences from sniffers and start the fingerprint-building phase.
VI. FINGERPRINT BUILDING & TRACKING
In this section, we detail the methodologies employed in the third and fourth phases. During the fingerprint-building phase, attackers preprocess the RSSI sequence data, detect the proximity of target devices to RAs, and build an RSSI fingerprint with a Reinforcement Learning system. In the last tracking phase, attackers use the RSSI fingerprint to track target devices in real time.
A. Fingerprint-Building: Motion Analyzer
Attackers begin by preprocessing the RSSI sequences obtained from data collection. As RFTrack’s objective is to recreate the actual movements of target devices during this collection phase, it’s essential to identify the movement periods within the RSSI sequences and isolate them for further processing. This movement analysis consists of two parallel steps: (i) Smoothing the raw RSSI sequence to eliminate minor fluctuations and noise, thus revealing a clearer pattern of movement. (ii) Extracting the sections of the sequence that correspond to movement periods, thereby filtering out periods of inactivity or static behavior. A typical raw RSSI sequence is shown in Fig. 4a. Given the inherent noise and high variability in raw RSSI values, RFTrack employs a smoothing technique to bring clarity to the data. The approach taken involves averaging the highest RSSI values within a sliding window because RSSI values mainly decrease rather than increase when obstacles interfere with signals. Thus, the upper bound for RSSI values is more stable than the lower bound. The results are shown in the blue curve in Fig. 4a.
Fig. 5. Moving periods extraction process.
In addition to RSSI data smoothing, RFTrack also needs to identify and isolate the moving periods. A previous work [50] accurately detects human motion with RSSI temporal and frequency domain features from multiple APs. Nevertheless, as RFTrack may use as few as only one sniffer, we consider an easier method of calculating variance of the variance (VoV) of RSSI. In Fig. 4a, the user stood still from 20 to 28 seconds and 35 to 45 seconds, during which the RSSI values exhibit relative stability. RFTrack calculates the VoV for a period and uses a threshold to distinguish moving states. Before calculating variances, outliers are removed, and only the middle 80% RSSI values are used for further process. As shown by the red curve in Fig. 5a, VoV is significantly low when the device is stationary. Fig. 5b illustrates an example of the identified moving periods.
B. Fingerprint-Building: Proximity to Reference Anchors
So far, attackers have located some RAs via the bootstrap and identified the moving periods during data collection, and they focus on identifying whether the target devices approach one of the RAs during their movements. There exist some works that detect “self-proximity” [51], [52] or coarsegrained “mutual-proximity” [53].1 However, RFTrack aims at detecting fine-grained mutual-proximity. Given the diversity of RAs, which include devices such as tablets and APs, their transmission characteristics often differ from those of the target devices. As such, a metric to determine proximity should minimize the impact of devicedependent features. To this end, we propose a new metric,
1Self-proximity means to detect whether another device is close to itself. Mutual-proximity means to detect whether the other two devices are close.
Authorized licensed use limited to: Southeast University. Downloaded on November 22,2024 at 08:07:19 UTC from IEEE Xplore. Restrictions apply.


LI et al.: RFTrack: STEALTHY LOCATION INFERENCE AND TRACKING ATTACK ON Wi-Fi DEVICES 5931
Fig. 6. Proximity detection with RSSI difference. In Fig. 6b, the three RSSID values at the red line constitute an R DVT D.
RSSI difference,2 which requires at least two sniffers to work. In this subsection, the RA and the target device are both referred to as “target” for ease of presentation. According to the LDPL model (equation 1), we formulate RSSI difference (RSSID) as follows, where i and j are the ids of sniffers, k is the id of a target, and X uniquely identifies an RSSID between the two sniffers.
R SS I D{X }k = R SS I i
k − RSSI j
k
= (Pk − 10γ i
k lg(di
k )) − (Pk − 10γ j
k lg(d j
k ))
= 10γ j
k lg(d j
k ) − 10γ i
k lg(di
k ) (3)
Pk is the only device-dependent factor, and RSSID nullifies it. The remaining factors, γ , and d, are determined by the relative positional relationship between sniffers and the target. Intuitively, when two targets, denoted as k1 and k2, are positioned closely, their γ and d to the sniffers are similar and thus exhibit similar RSSID values. Therefore, by examining the similarity between RSSIDs, attackers could infer the proximity of the two targets. To make the detection more convincing, attackers use more sniffers and apply similarity examination to all RSSIDs, as shown in Fig. 6a. In this particular scenario, data from three sniffers yields three distinct RSSID combinations, which collectively form an RSSI Difference Vector (RDV), denoted as R DVR A = [R S S I D1R A, R S S I D2R A, R S S I D3R A]. We measure the proximity between TD and RA with the Euclidean distance (∥R DVR A − R DVT D∥2) between two RDVs (RDVD). In our described attack scenario, attackers aim to detect whether a target device approached one of the RAs during data collection. R DVR A can be easily obtained because the RA is static over time. To derive the time-varying R DVT D values, RSSID can be computed from the collected RSSI sequences across the three sniffers, as depicted in Fig. 6b. By traversing across the timeline, attackers can discover “moments” when R DVT Ds closely match R DVR A. These specific “moments” are labeled as Mprox and will assist the subsequent model training in Sec. VI-C.
C. Fingerprint-Building: Reinforcement Learning Process
In this step, attackers construct a fingerprint map leveraging all the previously discussed information. Specifically, attackers
2Although [52] also uses the term “RSSI difference,” it differs from ours.
Fig. 7. Simplified structure of the RL system. ENV contains an agent, a gridified map, and a discretized RSSI sequence. In step one, the agent consults the RL algorithm on moving. In step two, the agent executes the movement and ENV maps an RSSIM to the position. In step three, ENV evaluate the current movement with reward feedback, and in step four, the RL algorithm learns how to improve the agent’s movements.
recover target devices’ moving trajectories via path simulation and consistency verification. Then, the RSSI sequences are aligned with the reconstructed trajectories to create a fingerprint map. To achieve so, attackers use a Reinforcement Learning system. A standard RL system comprises three components: (i) a simulation environment, (ii) an RL agent that interacts with the environment and gets feedback, and (iii) an RL algorithm that learns to improve the agent’s behavior to achieve better overall performance. Within this framework, the RL system tailored for RFTrack functions as follows: First, an RL agent acting as the target device is inside a simulated PoI environment (ENV) and moves. It observes its current position inside the PoI and chooses a prospective moving direction. Based on the current state (position) and the chosen action (moving direction), ENV employs consistency checking, i.e., aligning RSSI sequences to the generated trajectories, to compute reward feedback for the agent. Such rewards indicate how the agent’s movements align with recovering the ground truth trajectories. Through iterations, the agent uses an RL algorithm to learn from the feedback on how to move in every step to eventually simulate trajectories that contain similar consistency information as the ground truth. The organization of the RL system is shown in Fig. 7. In the following subsections, we elaborate on the simulation environment (ENV), the states and action spaces of the agents, the training iteration, the reward mechanisms of ENV, the architecture of the network, and the training techniques.
1) Simulation Environment: Attackers construct a simulation environment (ENV) to emulate the movements of target devices during the data collection phase. For ease of computation, we consider discrete agent’s movements, that is, both the ENV map and time are discrete. To this end, ENV first uses a publicly accessed floor plan to roughly build a gridified map of the PoI. Such a map contains hard obstacles, such as walls, to constrain the agent’s movement. Meanwhile, ENV discretizes RSSI sequences by separating them into fixed-length pieces and using the average value of each piece to represent the RSSI measurement (RSSIM) for a specific moment. Fig. 4b depicts a discretized RSSIM sequence of the moving periods. In our experiments, ENV adopts the discretizing granularity of 0.5 meters for the grid’s side length
Authorized licensed use limited to: Southeast University. Downloaded on November 22,2024 at 08:07:19 UTC from IEEE Xplore. Restrictions apply.


5932 IEEE TRANSACTIONS ON INFORMATION FORENSICS AND SECURITY, VOL. 19, 2024
and 0.7 seconds for an RSSI sequence piece. The setting of these parameters depends on the average walking speed in different environments, e.g., people may walk faster in an office than at home. 2) State & Actions: Within ENV, the agent moves discretely as time step changes. At each time step, the agent occupies a specific grid defined by a coordinate, and ENV uses the term state to record the agent’s current coordinate. As time progresses, the agent can move in nine directions (action), provided the chosen direction is not obstructed, as shown in Fig. 7. If the agent stays at the same grid or moves into an obstacle, its coordinate remains unchanged. Otherwise, the agent adjusts its coordinate.
Algorithm 1 Single Iteration of Simulation 1: Input: initial position init_ pos, RSSIM list R SS I MLst , 2: and initial state state
3: R S S I MLst ← [r ssi m0, . . . , r ssi mT −1] 4: state. pos ← init_ pos 5: state. pos.r ssi m ← R SS I MLst [0] 6: pr ev_states ← [] 7: r ewar ds ← [] 8: pr ev_states.append(state) 9: for all t ∈ {1, . . . , T } do
10: select an action based on the pr ev_states 11: excute the action and reach next_state 12: next_state. pos ← new_ pos
13: if never been to next_state. pos then
14: next_state. pos.r ssi m ← R SS I MLst [t] 15: end if
16: calculate r ewar d with next_state and pr ev_states 17: state ← next_state 18: r ewar ds.append(r ewar d) 19: pr ev_states.append(state) 20: end for
21: Output: a state sequence and a r ewar d sequence
3) Simulation Process (Training): We outline the general RL system training process on top of the previous definitions of ENV and state-action. Algo. 1 shows one iteration of training. In this example, ENV discretizes an RSSI sequence into RSSIMs with the length of T . Here, t symbolizes the current time step, starting with t = 0. Before initiating the “For” loop, ENV sets the starting coordinate, init_ pos, as the agent’s initial state. Meanwhile, it assigns r ssim0 to the position of such an initial state on the ENV map. Within the loop, as the time step advances, the agent chooses an action based on the current state and all previous states. After the action, the agent reaches a new state, next_state, and updates its current position as next_state. pos. If next_state. pos is an unexplored position for the agent, ENV associates R SS I MLst [t] to next_state. pos. Last, ENV computes rewards (by examining RSSIM consistency) as feedback. The training iteration concludes after T time steps, resulting in the agent having traversed T distinct states. These states contain consecutive temporal and spatial information, thus constituting a simulated trajectory. Moreover, the agent will
also earn accumulated rewards for all its movements in each iteration, and we anticipate that the agent will learn from such information to recover the ground truth trajectories eventually. 4) Rewarding Mechanisms: Through iterations of the above simulation, attackers obtain numerous potential trajectories and expect higher rewards for those closely aligned with the ground truth. The key to such results is the design of a rewarding mechanism, enabling the agent to learn the generation of such trajectories. This is achieved with the consistency-based rewarding mechanism, as previously discussed in Sec. IV-A. During a simulation iteration, ENV maps R SS I M[t] to positions along the agent’s trajectory. If the trajectory contains multiple identical (or nearby) positions, ENV assesses the similarities among the corresponding R SS I Ms. Positive rewards are given if they are consistent, and vice versa. It is worth mentioning that if attackers deploy several sniffers, consistency verification is applied to all RSSIM sequences simultaneously. In summary, when the agent simulates a path close to the ground truth, we expect such a trajectory to show strong self-consistency and thus get high rewards. 5) RL Algorithm: An RL algorithm takes (state, action, r ewar d) as the input to learn how to increase accumulated rewards, essentially guiding the agent in producing consistent trajectories. In RFTrack, we adopt the deep recurrent Q network (DRQN) [54] as the RL algorithm. In the past, some works have underscored the efficacy of incorporating a recurrent neural network (RNN) into a deep Q network (DQN) to improve the overall performance [54], [55]. Nevertheless, RFTrack is motivated to use DRQN because DQN can only learn from a single state while the “knowledge” to be learned in RFTrack is hidden in state sequences. During the simulation, ENV rewards the agent with consistency verification, which depends on the current state and previous states. Consequently, our network input must accommodate the varying lengths of state sequences. To this end, we design a network structure with a double-layer long short-term memory (LSTM) network at the forefront, succeeded by layers of perceptrons. The LSTM layer extracts features from state sequences, which then informs the subsequent layers to calculate Q values [56], guiding the agent’s action selection. Throughout the training process, we use epsilon-greedy to increase the randomness of action choices. In order to speed up the convergence, an experience replay buffer is used to store (state, action, r ewar d) tuples. 6) Training Assistance: We further introduce some mechanisms to overcome challenges during training. Within the ENV, obstacles on the floor plan constrain the agent’s movements. However, depending on the structure of a PoI, the agent may hardly reach certain positions or generate certain trajectories, even if they align with the ground truth. For instance, a large free space can entrap the agent, preventing it from exploring elsewhere. In such cases, the agent constantly receives negative rewards due to the inability to make useful movements. To solve this problem, ENV adopts Intermediate Destination Selection (IDS) and Random IDS (RIDS) in certain training iterations. We regard a device’s movement as a process consisting of multiple intermediate destinations, i.e., where it stops at or
Authorized licensed use limited to: Southeast University. Downloaded on November 22,2024 at 08:07:19 UTC from IEEE Xplore. Restrictions apply.


LI et al.: RFTrack: STEALTHY LOCATION INFERENCE AND TRACKING ATTACK ON Wi-Fi DEVICES 5933
passes by. IDS helps select definitive intermediate destinations for the agent. In Sec. VI-B, attackers had identified some definitive moments Mprox when target devices approached known RAs. This provides clues that the agent should also approach certain RAs’ areas at certain moments during the simulation. By forcing the agent to visit those areas, ENV prevents the former from getting stuck. Moreover, ENV introduces RIDS to select random intermediate destinations as complementary information. During RSSI data processing, sequences are segmented into moving periods. Thus, given that RSSI data sequences are divided into specific moving periods and considering the initial position and moving period, there’s a finite range within which the agent can reach. Within this range, RIDS chooses random points, pushing the agent to explore areas it might not visit during regular training. It is worth mentioning that compared to regular training iterations, IDS (and RIDS) will force the agent to make certain movements to ensure the latter reaches the chosen destination within a fixed period. To avoid model overfitting, however, ENV only guarantees that the agent tends to close in the destination instead of strictly reaching it. In summary, IDS and RIDS are used during training to speed up model convergence, and they are especially important for complicated PoI. Until now, attackers have finished all the training and recovered satisfying trajectory results. They map RSSI sequences to the trajectories to build a fingerprint map and use such a map to track target devices in real time.
D. Tracking
Upon constructing the fingerprint map, attackers utilize it for real-time tracking. In the tracking phase, attackers continue using the deployed sniffers to collect RSSI data from target devices. For any newly acquired RSSI values, attackers could search the fingerprint map to find a location with the closest RSSI match. To increase the tracking performance, we use “future” consecutive moments of an RSSI sequence to increase the accuracy of identifying devices’ initial locations and movements. For an RSSI piece containing n steps of movements, we find a n-step RSSIMs from the fingerprint map such that the latter has the closest alignment with the entire RSSI segment. We then select the first step in that path as the next movement step. Obviously, the further RFTrack looks into future RSSI values, the more accurate the tracking will be.
VII. EXPERIMENT EVALUATION
In this section, we evaluate the performance of RFTrack. We first introduce our experimental environment and settings. Then, we separately evaluate individual RFTrack subsystems and assess the attacking performance comprehensively.
A. Environments & Setups
1) Place of Interest & Sniffer Placement: Our experimental setup encompasses two distinct indoor environments to simulate typical places frequented by individuals: an apartment with a long, narrow corridor and a laboratory featuring extensive open areas. These settings reflect common locales where
Fig. 8. Floor plans.
people spend considerable time, such as their residences and workplaces. The floor plans, along with the arrangement of sniffers, are illustrated in Fig. 8. In the apartment setting, we opt not to utilize reference anchors, focusing instead on the natural constraints of the environment. Conversely, the laboratory setup incorporates obstacles that are observable from the exterior. The exact positions of these obstacles remain unmeasured to limit the attacker’s knowledge. This decision underlines our commitment to a realistic adversarial context, where exhaustive environmental data might not be readily accessible. The experimental design anticipates that the RSSI readings captured by the sniffers will be highly responsive to movements of the device in any direction. Therefore, the sniffers are strategically placed at regular intervals around the target area. This configuration aims to maximize the sensitivity of the system to device movement, ensuring comprehensive coverage and enhancing the fidelity of the tracking mechanism. 2) Target Devices, RAs, and Data Collection: The experiment concentrates on utilizing the 2.4GHz Wi-Fi frequency due to its effective obstacle penetration capabilities and extensive support across various devices. Within the laboratory setting, we typically select a TP-Link AC1200 router, a Huawei tablet, and a Xiaomi 8 smartphone as reference anchors to represent RAs with potentially different transmission power. In both indoor environments, a tester carries a Xiaomi 12 mobile device in his pocket and moves naturally, mimicking the behavior of a typical user, to generate the RSSI sequence data required for collection. During intervals between movements, the tester maintains a stationary position, either standing or sitting, as would be typical in everyday usage scenarios.
3) Ground Truth RSSI Fingerprints: To assess the efficacy of RFTrack, we conduct a comparative analysis between the ground truth fingerprint (GTF) map and the reconstructed version. The GTF map is generated by situating the target device (Xiaomi 12) at various locations within the PoI and recording its RSSI data. For each position, the average RSSI value over a 5-second interval is logged as its respective RSSI. The GTF maps of the two environments are shown in Sec. VII-E.
B. Bootstrap
We assess the bootstrap’s performance by measuring the error distance between the ground truth and the inferred locations. The target device is strategically positioned at five
Authorized licensed use limited to: Southeast University. Downloaded on November 22,2024 at 08:07:19 UTC from IEEE Xplore. Restrictions apply.


5934 IEEE TRANSACTIONS ON INFORMATION FORENSICS AND SECURITY, VOL. 19, 2024
Fig. 9. Losses and rewards during training.
distinct locations, followed by multiple rounds of dead reckoning. As shown in Fig. 9a, the localization performs well in the first four positions but the accuracy drops significantly in the last one, due to its low RSSI data quality. According to our observation, low-quality data usually has lower average RSSI values and fluctuates more severely than high-quality ones. RFTrack can quantitatively evaluate data quality with a reliability analysis. As mentioned earlier, attackers use the final loss at convergence, or more specifically, the correlation between the localization performance and the final loss (data qualities), to evaluate the overall reliability of the collected data. We use a group of dead reckoning data with good localization results as the baseline. 60% of the baseline data is perturbed randomly at different scales to generate groups of data with different quality, each of which adopts the same localization algorithm. The results are shown in Fig. 9b. The box with the lowest loss shows the baseline results. As more perturbation is added to the data, the average loss at convergence increases so does the variance of distance errors. These results are consistent with our expectation that diminished data quality (consistency) correlates with inferior localization performance. Moreover, the results indicate that our localization mechanism is robust against bad data quality — it constantly delivers reliable results until an average loss threshold of 2,000 is reached. In summary, the loss at convergence serves as a reliable indicator for the attackers to decide whether or not to use current dead reckoning data for bootstrap localization.
C. Proximity Detection
We evaluate the performance of proximity detection by examining the dependency of the size of the proximity areas on RSSI difference vector distances (RDVD). The experiment measures the proximity between the target device and Anchor2, an AC1200 router surrounded by regular objects that may interfere with signal propagation. We deploy the sniffers and the anchor to obtain R DVR A as in Sec. VI-B. Then we measure R DVT Ds by placing the target device at surrounding positions of the RA and compute RDVDs between them. The results are depicted in Fig. 10. When selecting varying RDVD thresholds, the dimensions of the proximity areas differ, yet they remain within certain limits. Therefore, attackers can use RDVD to detect proximity between devices and even to distinguish different levels of proximity depending on how small the RDVD is. Another observation is that the proximity area shows bias in different
directions as opposed to a circle. There are two reasons for this phenomenon. Firstly, the relative positional relationships between sniffers and the RA create such bias. When a device moves toward a certain direction, the changing gradients of RSSI values on different sniffers vary. Therefore, RSSID may become more sensitive to the distance in certain directions than others. Secondly, obstacles, such as metal materials or walls, significantly interfere with signal propagation, making the RDV values not similar despite the physical closeness of devices. In general, these effects exert a minimal impact on the optimal functioning of the system, primarily resulting in false negatives rather than false positives.3 Nonetheless, attackers could at least partially mitigate such bias by better placing the sniffers. Fig. 11 shows both a good and a bad example for reference. In summary, RDV distance can effectively represent the physical proximity between two devices. In the rest of the experiments, the proximity threshold is set to 3 meters.
D. Trajectory Recovery
In the following subsections, we evaluate RFTrack’s performance regarding fingerprint map building and tracking. First of all, the recovered trajectories are illustrated in Fig. 12 together with the ground truth ones. Generally, RFTrack effectively captures movement trends in most scenarios but struggles to precisely determine trajectories within rooms. Our justifications for such results are as follows. All indoor spaces can be categorized into two types, node: free-moving spaces and edges: connecting pathways. Inside a free-moving space, users can move freely with fewer constraints. On the contrary, users can only move along regulated routes on a connecting pathway. Under such a model, the user’s movements can always be described as a routine — he/she moves freely in a node or transitions via an edge to another node. Due to the lack of knowledge about the exact structures inside the PoI, RFTrack often cannot recover his/her exact movements. The best performance RFTrack can achieve is to detect when the agent leaves a node, moves on an edge, and enters a new node. Consequently, if attackers seek finer granularity in free spaces, they require either additional reference anchors or a more comprehensive understanding of the specific architectural details. Despite its effectiveness, RFTrack occasionally shows inaccuracies in trajectory recovery, as depicted in Fig. 12b. Such inaccuracies can be attributed to the lack of RSSI sequence diversity. For example, a sequence that captures only a single movement between positions will inevitably lead to recovery failure. Extending it to more general cases, RFTrack cannot differentiate between symmetric trajectories, such as moving from Room1 to the kitchen versus the living room, as illustrated in Fig. 13. Nonetheless, indoor floor plans may be symmetric in a small region but not globally. To counteract these inaccuracies, one practical solution is to simply gather longer RSSI sequences. The inclusion of more RAs and extended moving periods enhances accuracy.
3FP: falsely detected as close; FN: falsely detected as not close. FP may cause false training results rather than degrading performance.
Authorized licensed use limited to: Southeast University. Downloaded on November 22,2024 at 08:07:19 UTC from IEEE Xplore. Restrictions apply.


LI et al.: RFTrack: STEALTHY LOCATION INFERENCE AND TRACKING ATTACK ON Wi-Fi DEVICES 5935
Fig. 10. Correlation between RDV and real distances. The grid size is 0.5m ∗ 0.5m. The center location is (16,16).
Fig. 11. Placement of sniffers on mitigating bias.
Fig. 12. Ground truth v.s. recovered trajectories.
Fig. 13. Symmetry of a subregion in the node-edge graph.
E. Fingerprint Building
Attackers construct the RSSI fingerprint map by associating the RSSI sequences with the recovered trajectories. The ground-truth fingerprint maps and the recovered ones are plotted in Fig. 14 for comparison. In the experiment, the ground truth fingerprint map only measures places where people can walk. As shown by the figure, our system does not reveal accurate RSSI fingerprints in the free spaces of the apartment. Consequently, our system cannot accurately (meter-level) localize a device inside the corresponding rooms. In the lab environment, the system fails to recover a portion of the RSSI fingerprint map because of the mistakes in trajectory recovery.
Fig. 14. Ground truth v.s. recovered RSSI fingerprint of one sniffer.
Nonetheless, the attackers still obtain necessary information for future tracking. First, in the apartment, both trends and exact values of RSSI along the corridor and pathways are precise, owing to the corridor being the sole connector between the bedrooms and the living room. Such results are essential for tracking a device’s movements. Second, although attackers do not fingerprint specific positions accurately, the RSSI ranges designated to particular areas are relatively precise, which is important for tracking a device entering and leaving an area. For both environments, we will later show that small mistakes in a portion of the fingerprint map do not degrade the overall tracking performance.
F. Localization & Tracking
We additionally generate some trajectories and collect their corresponding RSSI sequences to assess the tracking performance. Fig. 16 shows the visualized tracking results. We evaluate the localization and tracking performance from two perspectives. First, the tracking efficacy of detecting node entrance and leaving is presented in Table I. We examine whether the system correctly localizes the starting and ending positions at room level. Second, since the newly generated trajectories are simple and do not contain duplicate positions, we use the minimum distance between a tracked position and a time-varying segment4 of the ground truth trajectory
4The segment of trajectory is part of the ground truth path that contains a sequence of “positions” which changes over time.
Authorized licensed use limited to: Southeast University. Downloaded on November 22,2024 at 08:07:19 UTC from IEEE Xplore. Restrictions apply.


5936 IEEE TRANSACTIONS ON INFORMATION FORENSICS AND SECURITY, VOL. 19, 2024
Fig. 15. Tracking performance evaluation. Each box contains error distance results corresponding to every positions on a tracked trajectory.
to discretely evaluate the real-time tracking errors. For every discrete position on a tracked path, shorter error distances imply better performance. The results are in Fig. 15. First of all, RFTrack is effective for room-level tracking and only mistakenly localizes the target device to a neighboring room within the lab setting. Regarding absolute error distance, our system also performs, with the majority of the tracking results maintaining error distances lower than 1.5 meters. Although the apartment with a simpler structure seems to have worse performance than the lab, it is only because we apply no constraints to the agent’s movements in the apartment ENV other than unremovable obstacles, e.g., walls. As a result, the fingerprint of the living room differs from the ground truth, which generates most error outliers. Overall, our adversarial tracking is effective in finding both the initial position and following movements. Since we can only track based on the recovered fingerprint map, the attack would momentarily fail if the target device arrives at an unvisited area. Nevertheless, identifying such a tracking lapse becomes straightforward in the absence of a closely aligned fingerprint. In such scenarios, the tracking would stop until a known matching RSSI fingerprint is detected.
VIII. DISCUSSION
In this section, we further discuss in depth on RFTrack’s enhancements, limitations, and mitigation methods.
A. Errors in the Bootstrap Localization
At the bootstrap, attackers locate target devices and RAs with a dead reckoning method. Although the localization outcomes are generally satisfactory, meter-scale errors still remain, potentially influencing subsequent proximity detection and possibly affecting the Intermediate Destination Selection (IDS) procedure during training and the overall system performance. Fortunately, our experimental findings suggest that the impact is negligible as long as localization errors are insignificant. This is because the system does not force the agent to be strictly close to specific RAs at particular moments during training. Instead, the system only ensures that the agent tends to approach an RA through IDS. Therefore, “the proximity to an RA” is converted to “the proximity to a larger area,” which mitigates the influence of minor localization errors of RAs. Moreover, this reinforces the need for the results’ reliability assessment for attackers. For the rare case of high localization errors, a benign location-based service may only navigate a
user to the wrong places, but attackers are at risk of being exposed or even caught.
B. Lack of RSSI Data Diversity
The lack of RSSI data diversity can degrade system performance. Because of this, RFTrack makes small mistakes on a portion of the results in the lab, and the best way of mitigating the problem is simply collecting longer RSSI sequences with higher diversity, expecting target devices to reach more spaces. However, this is indeed out of the attackers’ control. There are two possible solutions. The first leverages the proximity information between a target device and the attacker’s sniffers. By lacing sniffers near some rooms with few or no Wi-Fi devices, attackers know whether the target device has approached these rooms. Consequently, these sniffers provide non-redundant proximity information besides RAs. The second strategy taps into the potentials of multi-agent reinforcement learning [57]. In the existing model, attackers deploy a singular agent (one target device) during the learning phase. Yet, in a typical PoI, multiple target devices are present, each potentially navigating unique paths and collectively cover more locations. Therefore, attackers could utilize their information simultaneously by putting multiple agents in the same training process. During this training, each agent simulates their own movements, and ENV examines both self-consistency and mutual consistency5 on the generated trajectories. In this case, simple RSSI cannot be used as the fingerprint anymore, as different devices have different transmitting power and thus different RSSI. To that end, RSSI differences or other features should be used instead. We leave such an advanced learning process as future work.
C. RSSI Noisiness Mitigation
During the data collection phase, especially when the target device is in motion with a user, RSSI readings can exhibit significant variability, potentially compromising the efficacy of the fingerprinting process. RFTrack addresses this challenge through a twofold strategy designed to alleviate the dependency on precise and stable RSSI measurements. Initially, to counteract the inherent fluctuations in RSSI data, the system computes the average of RSSI values over a brief interval. Moreover, RFTrack adopts a strategy of approximate RSSI sequence matching, as opposed to relying on exact matches of individual RSSI readings. This approach is predicated on the observation that while specific RSSI values for a given location may vary due to momentary factors, the overall pattern or sequence of RSSI readings along a trajectory tends to maintain a degree of consistency. Thus, minor discrepancies in positional RSSI values do not significantly detract from the resemblance of entire RSSI sequences corresponding to the same trajectory. Additionally, the presence of multiple sniffers collects various RSSI sequences, which further mitigates the nosiness of single RSSI values.
5When a device reaches a place that another device has been to, consistency checking is also applied.
Authorized licensed use limited to: Southeast University. Downloaded on November 22,2024 at 08:07:19 UTC from IEEE Xplore. Restrictions apply.


LI et al.: RFTrack: STEALTHY LOCATION INFERENCE AND TRACKING ATTACK ON Wi-Fi DEVICES 5937
Fig. 16. Ground truth trajectories and tracking results.
TABLE I
ROOM-LEVEL DETECTION RESULTS
D. Limitations & Risk Analysis
RFTrack has its limitations. For example, the attack specializes in tracking devices rather than locating persons as [16] and [31]. In addition, it cannot support attacks on large open spaces where little is known about the detailed structures inside, specifically, the walking paths. Moreover, the success of RFTrack is also contingent upon the density and positioning of reference anchors. Consequently, we cannot apply this attack to any random indoor environment. Those PoIs with more narrow pathways are more suitable for RFTrack and may lead to finer localization and tracking results. Given these constraints, it’s not feasible for attackers to always succeed. Therefore, from the attackers’ perspective, knowing the reliability of these results is essential. For RFTrack, the reliability can be assessed by observing the recovered trajectories and the constructed RSSI fingerprint map. For instance, the trajectories diverge from typical normal human movement patterns or the built RSSI map contradicts the principles of signal propagation, e.g., farther places have abnormally higher RSSI values or a place’s RSSI exceedingly differs from its surroundings. Meanwhile, some seemingly correct minor errors are the trade-off between high performance and the risk of being disclosed, i.e., deploying more sniffers to get more information. Therefore, this kind of limitation is acceptable to attackers.
E. Mitigation
There are some ways to mitigate this attack. First, attackers exploit a design flaw in IEEE 802.11 to wake devices from power-saving mode and achieve high-frequency sniffing actively. If such a flaw can be fixed, attackers cannot continuously capture the signals from target devices when they are moving. However, this may not be feasible since such
a “flawed” mechanism may guarantee the wireless network performance. In addition, our attack is not limited to the Wi-Fi protocol. For instance, most mobile devices constantly communicate with base stations over the cellular network, which can also be a potential medium for our attack. A more holistic deterrent would be to employ dynamic transmission power levels for signals. Such a method can fundamentally stop attackers from building static fingerprint maps. Additionally, we suggest A continuous modulation in transmission power could be more effective than discrete step adjustment. Due to the stability of RSSI, step adjustment of power may be easily detected by machine learning methods, and attackers can discern underlying patterns and subsequently counteract the protective measures. On the contrary, continuous adjustment can be seamlessly blended with the inherent fluctuations of RSSI caused by the device’s movements, making the detection exceedingly challenging.
IX. CONCLUSION
In this study, we introduce RFTrack, an attack designed to highlight the potential for indoor location privacy breaches stemming from Wi-Fi-enabled devices. RFTrack neither necessitates cumbersome equipment nor requires prior physical access to the area of interest. Initially, attackers employ an adversarial dead reckoning approach to estimate the starting positions of both the target mobile devices and some stationary Wi-Fi anchors within the place of interest. By systematically capturing the time-sequenced unlabeled RSSI data from these devices, we leverage reinforcement learning techniques to infer possible movement paths, subsequently creating an RSSI fingerprint map by correlating these paths with the physical layout of the premises. To enhance the accuracy of our adversarial localization, we introduce an metric named RSSI difference to assess the proximity of the target devices to the stationary Wi-Fi devices within the PoI. Through system evaluations, we demonstrate the efficacy and robustness of RFTrack in accurately localizing and tracking devices.
Authorized licensed use limited to: Southeast University. Downloaded on November 22,2024 at 08:07:19 UTC from IEEE Xplore. Restrictions apply.


5938 IEEE TRANSACTIONS ON INFORMATION FORENSICS AND SECURITY, VOL. 19, 2024
REFERENCES
[1] N. News. (Apr. 2022). Watch: La Burglary Caught on Camera While Homeowner Hides in Bathroom. Accessed: Aug. 9, 2023. [Online]. Available: https://www.youtube.com/watch?v=BL4S6t_xNOE
[2] S. C. M. Post. (Jan. 2024). Burglar Steals Hk$1 Million in Luxury Watches From Home of Hong Kong Businessman. Accessed: Mar. 29, 2024. [Online]. Available: https://www.scmp.com/news/hongkong/law-and-crime/article/3249040/hong-kong-businessman-fallsvictim-break-after-thief-makes-hk1-million-luxury-watches-his-home [3] J. Xiong and K. Jamieson, “ArrayTrack: A fine-grained indoor location system,” in Proc. USENIX Symp. Netw. Syst. Design Implement., 2013, pp. 71–84. [4] M. Kotaru, K. Joshi, D. Bharadia, and S. Katti, “SpotFi: Decimeter level localization using WiFi,” in Proc. ACM Conf. Special Interest Group Data Commun., Aug. 2015, pp. 269–282. [5] A. Abedi and D. Vasisht, “Non-cooperative Wi-Fi localization & its privacy implications,” in Proc. 28th Annu. Int. Conf. Mobile Comput. Netw., Oct. 2022, pp. 570–582. [6] Espressif. Esp32 Datasheet, Expressive System. Accessed: Aug. 9, 2023. [Online]. Available: https://www.espressif.com/en/products/socs/esp32 [7] F. Liu et al., “Survey on wifi-based indoor positioning techniques,” IET Commun., vol. 14, no. 9, pp. 1372–1383, 2020. [8] I. A. Junglas and R. T. Watson, “Location-based services,” Commun. ACM, vol. 51, no. 3, pp. 65–69, 2008. [9] L. Tang, Q. Ye, H. Hu, and M. H. Au, “Secure traffic monitoring with spatio-temporal metadata protection using oblivious RAM,” IEEE Trans. Intell. Transp. Syst., vol. 24, no. 12, pp. 14903–14913, Dec. 2023. [10] H. Hu, Q. Chen, J. Xu, and B. Choi, “Assuring spatio-temporal integrity on mobile devices with minimum location disclosure,” IEEE Trans. Mobile Comput., vol. 16, no. 11, pp. 3000–3013, Nov. 2017. [11] L. Tang and H. Hu, “OHEA: Secure data aggregation in wireless sensor networks against untrusted sensors,” in Proc. 29th ACM Int. Conf. Inf. Knowl. Manage., Oct. 2020, pp. 1425–1434. [12] D. Vasisht, S. Kumar, and D. Katabi, “Decimeter-level localization with a single WiFi access point,” in Proc. 13th USENIX Symp. Netw. Syst. Design Implement. (NSDI), 2016, pp. 165–178.
[13] J. Gjengset, J. Xiong, G. McPhillips, and K. Jamieson, “Phaser: Enabling phased array signal processing on commodity WiFi access points,” in Proc. 20th Annu. Int. Conf. Mobile Comput. Netw., Sep. 2014, pp. 153–164. [14] J. Xiong, K. Sundaresan, and K. Jamieson, “Tonetrack: Leveraging frequency-agile radios for time-based indoor wireless localization,” in Proc. 21st Annu. Int. Conf. Mobile Comput. Netw., 2015, pp. 537–549. [15] X. Wang, L. Gao, S. Mao, and S. Pandey, “CSI-based fingerprinting for indoor localization: A deep learning approach,” IEEE Trans. Veh. Technol., vol. 66, no. 1, pp. 763–776, Jan. 2017. [16] F. Wang, S. Zhou, S. Panev, J. Han, and D. Huang, “Person-in-WiFi: Fine-grained person perception using WiFi,” in Proc. IEEE/CVF Int. Conf. Comput. Vis. (ICCV), Oct. 2019, pp. 5451–5460.
[17] A. Rai, K. K. Chintalapudi, V. N. Padmanabhan, and R. Sen, “Zee: Zero-effort crowdsourcing for indoor localization,” in Proc. 18th Annu. Int. Conf. Mobile Comput. Netw., Aug. 2012, pp. 293–304.
[18] S. Lanzisera, “RF time of flight ranging for wireless sensor network localization,” in Proc. Int. Workshop Intell. Solutions Embedded Syst., Vienna, Austria, Dec. 2006, pp. 165–176. [19] R. Peng and M. L. Sichitiu, “Angle of arrival localization for wireless sensor networks,” in Proc. 3rd Annu. IEEE Commun. Soc. Sensor Ad Hoc Commun. Netw., Sep. 2006, pp. 374–382. [20] X. Li, Z. D. Deng, L. T. Rauchenstein, and T. J. Carlson, “Contributed review: Source-localization algorithms and applications using time of arrival and time difference of arrival measurements,” Rev. Sci. Instrum., vol. 87, no. 4, Apr. 2016, Art. no. 041502. [21] E. Soltanaghaei, A. Kalyanaraman, and K. Whitehouse, “Multipath triangulation: Decimeter-level WiFi localization and orientation with a single unaided receiver,” in Proc. 16th Annu. Int. Conf. Mobile Syst. Appl. Service (MobiSys), 2018, pp. 376–388.
[22] Q. Li et al., “AF-DCGAN: Amplitude feature deep convolutional GAN for fingerprint construction in indoor localization systems,” IEEE Trans. Emerg. Topics Comput. Intell., vol. 5, no. 3, pp. 468–480, Jun. 2021. [23] T. Jiang, H. J. Wang, and Y.-C. Hu, “Preserving location privacy in wireless LANs,” in Proc. 5th Int. Conf. Mobile Syst., Appl. services, San Juan, Puerto Rico, Jun. 2007, pp. 246–257.
[24] X. He, R. Jin, and H. Dai, “Leveraging spatial diversity for privacy-aware location-based services in mobile networks,” IEEE Trans. Inf. Forensics Security, vol. 13, no. 6, pp. 1524–1534, Jun. 2018. [25] Z. Montazeri, A. Houmansadr, and H. Pishro-Nik, “Achieving perfect location privacy in wireless devices using anonymization,” IEEE Trans. Inf. Forensics Security, vol. 12, no. 11, pp. 2683–2698, Nov. 2017. [26] X. Wang, Y. Mu, and R. Chen, “One-round privacy-preserving meeting location determination for smartphone applications,” IEEE Trans. Inf. Forensics Security, vol. 11, no. 8, pp. 1712–1721, Aug. 2016. [27] I. Bang, T. Kim, H. S. Jang, and D. K. Sung, “An opportunistic power control scheme for mitigating user location tracking attacks in cellular networks,” IEEE Trans. Inf. Forensics Security, vol. 17, pp. 1131–1144, 2022. [28] J. D. Roth, M. Tummala, J. C. McEachen, and J. W. Scrofani, “On location privacy in LTE networks,” IEEE Trans. Inf. Forensics Security, vol. 12, no. 6, pp. 1358–1368, Jun. 2017. [29] Y. Li, J. Zhu, Z. Liu, M. Tang, and S. Ren, “Deep learning gradient visualization-based pre-silicon side-channel leakage location,” IEEE Trans. Inf. Forensics Security, vol. 19, pp. 2340–2355, 2024.
[30] A. B. M. Musa and J. Eriksson, “Tracking unmodified smartphones using Wi-Fi monitors,” in Proc. 10th ACM Conf. Embedded Netw. Sensor Syst., Toronto, ON, Canada, Nov. 2012, pp. 281–294. [31] Y. Zhu et al., “Et tu Alexa? When commodity WiFi devices turn into adversarial motion sensors,” in Proc. Netw. Distrib. Syst. Secur. Symp., 2020. [32] Z. Chen, H. Hu, and J. Yu, “Privacy-preserving large-scale location monitoring using Bluetooth low energy,” in Proc. 11th Int. Conf. Mobile Ad-Hoc Sensor Netw. (MSN), Shenzhen, China, Dec. 2015, pp. 69–78. [33] H. Zheng and H. Hu, “MISSILE: A system of mobile inertial sensor-based sensitive indoor location eavesdropping,” IEEE Trans. Inf. Forensics Security, vol. 15, pp. 3137–3151, 2020. [34] H. Hu, J. Xu, and D. L. Lee, “PAM: An efficient and privacy-aware monitoring framework for continuously moving objects,” IEEE Trans. Knowl. Data Eng., vol. 22, no. 3, pp. 404–419, Mar. 2010. [35] H. Hu and J. Xu, “2PASS: Bandwidth-optimized location cloaking for anonymous location-based services,” IEEE Trans. Parallel Distrib. Syst., vol. 21, no. 10, pp. 1458–1472, Oct. 2010. [36] H. P. Li, H. Hu, and J. Xu, “Nearby friend alert: Location anonymity in mobile geosocial networks,” IEEE Pervasive Comput., vol. 12, no. 4, pp. 62–70, Oct. 2013. [37] J. Du, J. Xu, X. Tang, and H. Hu, “IPDA: Supporting privacy-preserving location-based mobile services,” in Proc. Int. Conf. Mobile Data Manage., Mannheim, Germany, May 2007, pp. 212–214. [38] X. Lin, H. Hu, H. P. Li, J. Xu, and B. Choi, “Private proximity detection and monitoring with vicinity regions,” in Proc. 12th Int. ACM Workshop Data Eng. Wireless Mobile Acess, New York, NY, USA, Jun. 2013, pp. 5–12. [39] H. Hu, Q. Chen, and J. Xu, “VERDICT: Privacy-preserving authentication of range queries in location-based services,” in Proc. IEEE 29th Int. Conf. Data Eng. (ICDE), Apr. 2013, pp. 1312–1315.
[40] M. W. Traunmueller, N. Johnson, A. Malik, and C. E. Kontokosta, “Digital footprints: Using WiFi probe and locational data to analyze human mobility trajectories in cities,” Comput., Environ. Urban Syst., vol. 72, pp. 4–12, Nov. 2018. [41] L. P. Kaelbling, M. L. Littman, and A. W. Moore, “Reinforcement learning: A survey,” J. Artif. Intell. Res., vol. 4, pp. 237–285, Jan. 1996. [42] J. Wang, J. Hu, G. Min, W. Zhan, Q. Ni, and N. Georgalas, “Computation offloading in multi-access edge computing using a deep sequential model based on reinforcement learning,” IEEE Commun. Mag., vol. 57, no. 5, pp. 64–69, May 2019. [43] P. Mirowski et al., “Learning to navigate in complex environments,” in Proc. 5th Int. Conf. Learn. Represent. (ICLR), Toulon, France, Apr. 2017. [44] J. Zhang, J. T. Springenberg, J. Boedecker, and W. Burgard, “Deep reinforcement learning with successor features for navigation across similar environments,” in Proc. IEEE/RSJ Int. Conf. Intell. Robot. Syst. (IROS), Sep. 2017, pp. 2371–2378. [45] M. Mohammadi, A. Al-Fuqaha, M. Guizani, and J.-S. Oh, “Semisupervised deep reinforcement learning in support of IoT and smart city services,” IEEE Internet Things J., vol. 5, no. 2, pp. 624–635, Apr. 2018. [46] Y. Li, X. Hu, Y. Zhuang, Z. Gao, P. Zhang, and N. El-Sheimy, “Deep reinforcement learning (DRL): Another perspective for unsupervised wireless localization,” IEEE Internet Things J., vol. 7, no. 7, pp. 6279–6287, Jul. 2020.
Authorized licensed use limited to: Southeast University. Downloaded on November 22,2024 at 08:07:19 UTC from IEEE Xplore. Restrictions apply.


LI et al.: RFTrack: STEALTHY LOCATION INFERENCE AND TRACKING ATTACK ON Wi-Fi DEVICES 5939
[47] Z. Li, Z. Xiao, Y. Zhu, I. Pattarachanyakul, B. Y. Zhao, and H. Zheng, “Adversarial localization against wireless cameras,” in Proc. 19th Int. Workshop Mobile Comput. Syst. Appl., New York, NY, USA, Feb. 2018, pp. 87–92. [48] L. Li, G. Shen, C. Zhao, T. Moscibroda, J.-H. Lin, and F. Zhao, “Experiencing and handling the diversity in data density and environmental locality in an indoor positioning service,” in Proc. 20th Annu. Int. Conf. Mobile Comput. Netw., Maui, HI, USA, Sep. 2014, pp. 459–470. [49] K. Chintalapudi, A. P. Iyer, and V. N. Padmanabhan, “Indoor localization without the pain,” in Proc. 16th Annu. Int. Conf. Mobile Comput. Netw., Sep. 2010, pp. 173–184. [50] K. Muthukrishnan, M. E. Lijding, N. Meratnia, and P. J. M. Havinga, “Sensing motion using spectral and spatial analysis of WLAN RSSI,” in Proc. Eur. Conf. Smart Sens. Context, vol. 4793, G. Kortuem, J. Finney, R. Lea, and V. Sundramoorthy, Eds. Cham, Switzerland: Springer, 2007, pp. 62–76. [51] T. J. Pierson, T. Peters, R. Peterson, and D. Kotz, “Proximity detection with single-antenna IoT devices,” in Proc. 25th Annu. Int. Conf. Mobile Comput. Netw., Aug. 2019, p. 21. [52] P. Sapiezynski, A. Stopczynski, D. K. Wind, J. Leskovec, and S. Lehmann, “Inferring person-to-person proximity using WiFi signals,” Proc. ACM Interact., Mobile, Wearable Ubiquitous Technol., vol. 1, no. 2, pp. 1–20, Jun. 2017. [53] H. Stange, T. Liebig, D. Hecker, G. Andrienko, and N. Andrienko, “Analytical workflow of monitoring human mobility in big event settings using Bluetooth,” in Proc. 3rd ACM SIGSPATIAL Int. Workshop Indoor Spatial Awareness, Chicago, IL, USA, Nov. 2011, pp. 51–58. [54] M. J. Hausknecht and P. Stone, “Deep recurrent Q-learning for partially observable MDPs,” in Proc. AAAI Fall Symp. Ser., 2015, pp. 29–37. [55] S. Kapturowski, G. Ostrovski, J. Quan, R. Munos, and W. Dabney, “Recurrent experience replay in distributed reinforcement learning,” in Proc. 7th Int. Conf. Learn. Represent. (ICLR), New Orleans, LA, USA, May 2019. [56] C. H. Watkins and P. Dayan, “Technical note Q-learning,” Mach. Learn., vol. 8, pp. 279–292, Jan. 1992. [57] K. Zhang, Z. Yang, and T. Basar, “Multi-agent reinforcement learning: A selective overview of theories and algorithms,” 2019, arXiv:1911.10635.
Ronghua Li received the B.Eng. degree from Huazhong University of Science and Technology in 2020 and the M.S. degree from EECS, KTH Royal Institute of Technology, in 2022. He is currently pursuing the Ph.D. degree with the Department of Electronic and Information Engineering, The Hong Kong Polytechnic University. His research interests include the IoT network security, smart home security, and human factors in the IoT.
Haibo Hu (Senior Member, IEEE) is currently a Professor with the Department of Electrical and Electronic Engineering, The Hong Kong Polytechnic University. He has published over 150 research papers in refereed journals, international conferences, and book chapters, and is granted five U.S. patents. As the Principal Investigator, he has received over 25 million HK dollars of external research grants from Hong Kong and mainland China. His research interests include cybersecurity, data privacy, and adversarial machine learning. He is a Senior Member of ACM and CCF and a certified Cisco CCNA Security Trainer. He was a recipient of a number of titles and awards, including the IWAIT 2021 Best Paper Award, the IEEE MDM 2019 Best Paper Award, the WAIM Distinguished Young Lecturer, the ICDE 2020 Outstanding Reviewer, the VLDB 2018 Distinguished Reviewer, the ACM-HK Best Ph.D. Paper, the Microsoft Imagine Cup, and the GS1 Internet of Things Award.
Qingqing Ye (Member, IEEE) received the Ph.D. degree from Renmin University of China in 2020. She is currnelty an Assistant Professor with the Department of Electrical and Electronic Engineering, The Hong Kong Polytechnic University. Her research interests include data privacy and security and adversarial machine learning. She was a recipient of several prestigious awards, including the Highly Cited Paper Award, the National Scholarship, and the IEEE S&P Travel Award.
Authorized licensed use limited to: Southeast University. Downloaded on November 22,2024 at 08:07:19 UTC from IEEE Xplore. Restrictions apply.